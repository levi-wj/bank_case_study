{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pickle import dump\n",
    "\n",
    "# Import train-test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the RandomForestClassifier and DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import metrics for evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "# Import Visualization Modules\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bank.csv\")\n",
    "mini = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bank_holdout_test_mini.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring unknown values\n",
    "\n",
    "In the categorical columns there are missing values labeled as 'unknown'. Here we find them so we can figure out what to do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9592, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unknown_mask = df.isin(['unknown'])\n",
    "\n",
    "# Filter the DataFrame to show rows with 'unknown' values\n",
    "unknown_rows = df[unknown_mask.any(axis=1)]\n",
    "unknown_rows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going a little deeper, here are the counts of unkown values in each categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default</td>\n",
       "      <td>7725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>education</td>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>housing</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loan</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>job</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>marital</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     0\n",
       "0    default  7725\n",
       "1  education  1535\n",
       "2    housing   894\n",
       "3       loan   894\n",
       "4        job   294\n",
       "5    marital    69"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a custom function to count \"unknown\" values\n",
    "def count_unknown(series):\n",
    "    return (series == 'unknown').sum()\n",
    "\n",
    "# Apply the function to each column using agg\n",
    "unknown_counts = df.agg(count_unknown).sort_values(ascending=False).reset_index()\n",
    "unknown_counts = unknown_counts[unknown_counts[0]> 0]\n",
    "unknown_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making connections\n",
    "\n",
    "Here we show some percentages to try and make connections between who has a term deposit and what key demographics they have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of people who have term deposits, by job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "student          31.399748\n",
       "retired          25.228162\n",
       "unemployed       14.676889\n",
       "admin.           13.127660\n",
       "unknown          11.904762\n",
       "management       11.442598\n",
       "technician       10.863831\n",
       "self-employed    10.753532\n",
       "housemaid         9.979210\n",
       "entrepreneur      8.639144\n",
       "services          8.258174\n",
       "blue-collar       6.819546\n",
       "Name: count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "((df[df['y'] == 'yes']['job'].value_counts() / df['job'].value_counts()) * 100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of people who have term deposits, by age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "98    100.000000\n",
       "89    100.000000\n",
       "87    100.000000\n",
       "92     75.000000\n",
       "86     71.428571\n",
       "         ...    \n",
       "49      6.710526\n",
       "47      6.521739\n",
       "91           NaN\n",
       "94           NaN\n",
       "95           NaN\n",
       "Name: count, Length: 78, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df[df['y'] == 'yes']['age'].value_counts() / df['age'].value_counts()) * 100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map y values to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    31406\n",
       "1     4176\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = df['y'].map({\"no\": 0, \"yes\": 1})\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 37069\n",
      "After 35582\n"
     ]
    }
   ],
   "source": [
    "print('Before', len(df))\n",
    "df = df.drop_duplicates()\n",
    "print('After', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce distinct values for Eurob3r\n",
    "\n",
    "Eurob3r has too many distinct values. Reducing the amount of these through rounding will help us to lessen the number of columns we have to deal with when we one-hot encode our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounding euribor3m\n",
      "Distinct vaues before: 314\n",
      "Distinct values after: 31\n"
     ]
    }
   ],
   "source": [
    "print('Rounding euribor3m')\n",
    "print('Distinct vaues before:', len(df['euribor3m'].value_counts()))\n",
    "df['euribor3m'] = df['euribor3m'].round(1)\n",
    "print('Distinct values after:', len(df['euribor3m'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Mini Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do same transformations as on the training set\n",
    "test = pd.get_dummies(mini)\n",
    "mini_predictions = t_model.predict(test)\n",
    "\n",
    "# Convert the predictions to a dataframe and label the column 'y'\n",
    "my_predictions = pd.DataFrame(mini_predictions, columns = ['y'])\n",
    "\n",
    "# Replace no with 0 and yes with 1\n",
    "my_predictions = my_predictions[\"y\"].replace({\"no\":0, \"yes\":1})\n",
    "\n",
    "# Replace PUTTEAMNUMBERHERE with your team\n",
    "my_predictions.to_csv(\"lilJiimy's-module2-predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full = []\n",
    "# i = 0\n",
    "# for test in np.arange(.1, .4, .05):\n",
    "#     for samp_size in range(50, 500, 100):\n",
    "#         for md in range(10, 200, 25):\n",
    "#             for wght in np.arange(.0, .55, .05):\n",
    "#                 acc, recall, pre = get_nums(test, md, samp_size, wght)\n",
    "#                 nummies = [test, samp_size, md, wght, acc, recall, pre]\n",
    "#                 full.append(nummies)\n",
    "#                 print(i)\n",
    "#                 i +=1\n",
    "\n",
    "# big = pd.DataFrame(full, columns=[\"test\", \"samp_size\", \"md\", \"wght\", \"acc\", \"recall\", \"pre\"])\n",
    "# big.to_csv(\"nummies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full = []\n",
    "# for test in np.arange(.1, .4, .05):\n",
    "#     for samp_size in range(50, 500, 100):\n",
    "#         for md in range(10, 200, 25):\n",
    "#             for wght in np.arange(.0, .55, .05):\n",
    "#                 nummies = [test, samp_size, md, wght]\n",
    "#                 full.append(nummies)\n",
    "\n",
    "# pd.DataFrame(full, columns=[\"test\", \"samp_size\", \"md\", \"wght\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big[(big[\"recall\"] > .7) & (big[\"acc\"] > .8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5207446808510638"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7845744680851063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8675282714054927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5476575121163166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.39601769911504425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7306034482758621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic One Hot encoding, data splitting, model training and testing\n",
    "\n",
    "X = pd.get_dummies(df.drop(\"y\", axis=1)).drop(\"default_yes\", axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15, random_state=42)\n",
    "\n",
    "#parameters\n",
    "md = 85\n",
    "min_samp = 150\n",
    "class_weight = np.where(y_train == \"no\", 0.15, 1.0)\n",
    "\n",
    "t_model = DecisionTreeClassifier(random_state=42, max_depth=md, min_samples_split=min_samp)\n",
    "f_model = RandomForestClassifier(random_state=42,\n",
    "    max_depth=17, \n",
    "    min_samples_split=min_samp,\n",
    "    n_estimators=100)\n",
    "\n",
    "t_model.fit(X_train, y_train, sample_weight=class_weight)\n",
    "f_model.fit(X_train, y_train)\n",
    "\n",
    "tree_predict = t_model.predict(X_test)\n",
    "for_predict = f_model.predict(X_test)\n",
    "\n",
    "tree_acc = accuracy_score(y_test, tree_predict)\n",
    "for_acc = accuracy_score(y_test, for_predict)\n",
    "tree_recall = recall_score(y_test, tree_predict, pos_label='yes')\n",
    "for_recall = recall_score(y_test, for_predict, pos_label='yes')\n",
    "tree_pre = precision_score(y_test, tree_predict, pos_label='yes')\n",
    "for_pre = precision_score(y_test, for_predict, pos_label='yes')\n",
    "\n",
    "\n",
    "display(tree_acc)\n",
    "display(for_acc)\n",
    "display(tree_recall)\n",
    "display(for_recall)\n",
    "display(tree_pre)\n",
    "display(for_pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Decision Tree.pkl\", \"wb\") as f:\n",
    "    dump(t_model, f, protocol=5)\n",
    "\n",
    "with open(\"Random Forest.pkl\", \"wb\") as f:\n",
    "    dump(f_model, f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131631001618413"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6511278195488722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.34919354838709676"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pickle import load\n",
    "with open(\"Decision Tree.pkl\", \"rb\") as f:\n",
    "    clf = load(f)\n",
    "\n",
    "tree_predict = t_model.predict(X_test)\n",
    "tree_acc = accuracy_score(y_test, tree_predict)\n",
    "\n",
    "tree_recall = recall_score(y_test, tree_predict, pos_label='yes')\n",
    "tree_pre = precision_score(y_test, tree_predict, pos_label='yes')\n",
    "\n",
    "display(tree_acc)\n",
    "display(tree_recall)\n",
    "display(tree_pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
